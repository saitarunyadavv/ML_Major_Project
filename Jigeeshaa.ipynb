{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigeeshaa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1Jigeesha/ML_Major_project/blob/main/Jigeeshaa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN3zS6YIGxY9"
      },
      "source": [
        "## **Sentiment Analysis on Tweets Using SVM(ML Algorithm)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rypAeVugR4oU",
        "outputId": "65ab99eb-4e4c-4210-9af9-6fd00e16488f"
      },
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.7.10 (default, May  3 2021, 02:48:31) \\n[GCC 7.5.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5tFnOqnkCKo"
      },
      "source": [
        "**Deployment of Web APP using Streamlit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPc3gD7wPtSM",
        "outputId": "e32b89b5-0773-4284-bd34-fee2ca1fe75c"
      },
      "source": [
        "!pip install streamlit --quiet\n",
        "!pip install pyngrok==4.1.1\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.8MB 25.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2MB 30.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 44.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 788kB 33.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 38.5MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.19 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 6.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.25.0 which is incompatible.\u001b[0m\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/a9/de2e15c92eb3aa4a2646ce3a7542317eb69ac47f667578ce8bf916320847/pyngrok-4.1.1.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-cp37-none-any.whl size=15985 sha256=9917f9b493fd2bd6c58937edc02e5f34dd7e13d20c20cdc7ae021f7be7c1cc2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/71/0d/1695f7c8815c0beb3b5d9b35d6eec9243c87e6070fbe3977fa\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u3QdlwmP1YK",
        "outputId": "c132418f-0034-4298-d370-a16a1c28dc4b"
      },
      "source": [
        "%%writefile app.py\n",
        "# It is a magic command to create a .py file\n",
        "import streamlit as st\n",
        "import joblib\n",
        "st.title('Tweets Sentiment Analysis Deployment')\n",
        "test_model = joblib.load('tweets_analysis')\n",
        "user_input = input(\"Enter the string: \")\n",
        "res = grid_svm.predict([user_input])\n",
        "if(res[0] == 0):\n",
        "  st.write(\"\\n Positive Tweet \\n\")\n",
        "else:\n",
        "  st.write(\"\\n Negative tweet \\n\")\n",
        "if st.button('Predict'):\n",
        "  st.title(res[0])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "pFB6TUHUP3ba",
        "outputId": "1c158e8f-f432-4a64-a843-a700fbfd6cd4"
      },
      "source": [
        "!nohup streamlit run app.py &\n",
        "url = ngrok.connect(port='8501')\n",
        "url"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'http://e048cc8e9239.ngrok.io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57oeiQgpjEJV"
      },
      "source": [
        "**1.1 Importing the required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZXfAfGAmM2G",
        "outputId": "2027e3b0-e873-4a77-e656-cd9b0a48c42f"
      },
      "source": [
        "#install tweet-preprocessor to clean tweets\n",
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24sRqc9ki4NS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt        #Visualisation\n",
        "import seaborn as sns                  #Visualisation\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BmeOpE6jNTp"
      },
      "source": [
        "**1.2 Reading the train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XMSKF-f2i5GP",
        "outputId": "bc773565-1cdd-4f23-a28f-f88a34d1dede"
      },
      "source": [
        "train = pd.read_csv(\"train_new.csv\")\n",
        "train.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wm6MkKEj0gP"
      },
      "source": [
        "**1.3 Entire information of Train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AYPI05DjQC6",
        "outputId": "8620387a-2998-40de-9035-6dd9603a7c7b"
      },
      "source": [
        "print(\"-------------------------------------------------------\\nChecking Null values\\n-------------------------------------------------------\")\n",
        "print(\" \" ,train.isnull().sum())\n",
        "print(\"-------------------------------------------------------\\nShape of the dataset\\n-------------------------------------------------------\")\n",
        "print(\" \",train.shape)\n",
        "print(\"-------------------------------------------------------\\nInformation of dataset\\n-------------------------------------------------------\")\n",
        "print(\"\", train.info())\n",
        "print(\"-------------------------------------------------------\\nDescription of the dataset\\n-------------------------------------------------------\")\n",
        "print(\"\",train.describe())\n",
        "print(\"-------------------------------------------------------\\nChecking duplication records\\n-------------------------------------------------------\")\n",
        "print(sum(train.duplicated()))\n",
        "print(\"-------------------------------------------------------\\nDroping the NaN values\\n-------------------------------------------------------\")\n",
        "\n",
        "print(train.dropna(axis='columns'))\n",
        "print(train.dropna(how='all'))\n",
        "print(\"-------------------------------------------------------\\nChecking for Null\\n-------------------------------------------------------\")\n",
        "print(train.isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Checking Null values\n",
            "-------------------------------------------------------\n",
            "  id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "-------------------------------------------------------\n",
            "Shape of the dataset\n",
            "-------------------------------------------------------\n",
            "  (7613, 5)\n",
            "-------------------------------------------------------\n",
            "Information of dataset\n",
            "-------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n",
            " None\n",
            "-------------------------------------------------------\n",
            "Description of the dataset\n",
            "-------------------------------------------------------\n",
            "                  id      target\n",
            "count   7613.000000  7613.00000\n",
            "mean    5441.934848     0.42966\n",
            "std     3137.116090     0.49506\n",
            "min        1.000000     0.00000\n",
            "25%     2734.000000     0.00000\n",
            "50%     5408.000000     0.00000\n",
            "75%     8146.000000     1.00000\n",
            "max    10873.000000     1.00000\n",
            "-------------------------------------------------------\n",
            "Checking duplication records\n",
            "-------------------------------------------------------\n",
            "0\n",
            "-------------------------------------------------------\n",
            "Droping the NaN values\n",
            "-------------------------------------------------------\n",
            "         id                                               text  target\n",
            "0         1  Our Deeds are the Reason of this #earthquake M...       1\n",
            "1         4             Forest fire near La Ronge Sask. Canada       1\n",
            "2         5  All residents asked to 'shelter in place' are ...       1\n",
            "3         6  13,000 people receive #wildfires evacuation or...       1\n",
            "4         7  Just got sent this photo from Ruby #Alaska as ...       1\n",
            "...     ...                                                ...     ...\n",
            "7608  10869  Two giant cranes holding a bridge collapse int...       1\n",
            "7609  10870  @aria_ahrary @TheTawniest The out of control w...       1\n",
            "7610  10871  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
            "7611  10872  Police investigating after an e-bike collided ...       1\n",
            "7612  10873  The Latest: More Homes Razed by Northern Calif...       1\n",
            "\n",
            "[7613 rows x 3 columns]\n",
            "         id keyword  ...                                               text target\n",
            "0         1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
            "1         4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
            "2         5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
            "3         6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
            "4         7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
            "...     ...     ...  ...                                                ...    ...\n",
            "7608  10869     NaN  ...  Two giant cranes holding a bridge collapse int...      1\n",
            "7609  10870     NaN  ...  @aria_ahrary @TheTawniest The out of control w...      1\n",
            "7610  10871     NaN  ...  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...      1\n",
            "7611  10872     NaN  ...  Police investigating after an e-bike collided ...      1\n",
            "7612  10873     NaN  ...  The Latest: More Homes Razed by Northern Calif...      1\n",
            "\n",
            "[7613 rows x 5 columns]\n",
            "-------------------------------------------------------\n",
            "Checking for Null\n",
            "-------------------------------------------------------\n",
            "id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNUPWS-vkWQZ"
      },
      "source": [
        "**1.4 Reading Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lbBTDKxukFC_",
        "outputId": "91b4f9c3-bfe1-4ec6-8d13-845c7369f24f"
      },
      "source": [
        "test = pd.read_csv(\"test_new.csv\")\n",
        "test.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXPDdoplkZIR"
      },
      "source": [
        "**1.5 Entire information of Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt_iS7OYjq8u",
        "outputId": "723063f7-f70f-4bd5-f9be-8a88cfe028b4"
      },
      "source": [
        "print(\"-------------------------------------------------------\\nChecking Null values\\n-------------------------------------------------------\")\n",
        "print(\" \" ,test.isnull().sum())\n",
        "print(\"-------------------------------------------------------\\nShape of the dataset\\n-------------------------------------------------------\")\n",
        "print(\" \",test.shape)\n",
        "print(\"-------------------------------------------------------\\nInformation of dataset\\n-------------------------------------------------------\")\n",
        "print(\"\", test.info())\n",
        "print(\"-------------------------------------------------------\\nDescription of the dataset\\n-------------------------------------------------------\")\n",
        "print(\"\",test.describe())\n",
        "print(\"-------------------------------------------------------\\nChecking duplication records\\n-------------------------------------------------------\")\n",
        "print(sum(test.duplicated()))\n",
        "print(\"-------------------------------------------------------\\nDroping the NaN values\\n-------------------------------------------------------\")\n",
        "\n",
        "print(test.dropna(axis='columns'))\n",
        "print(test.dropna(how='all'))\n",
        "print(\"-------------------------------------------------------\\nChecking for Null\\n-------------------------------------------------------\")\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Checking Null values\n",
            "-------------------------------------------------------\n",
            "  id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n",
            "-------------------------------------------------------\n",
            "Shape of the dataset\n",
            "-------------------------------------------------------\n",
            "  (3263, 4)\n",
            "-------------------------------------------------------\n",
            "Information of dataset\n",
            "-------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        3263 non-null   int64 \n",
            " 1   keyword   3237 non-null   object\n",
            " 2   location  2158 non-null   object\n",
            " 3   text      3263 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 102.1+ KB\n",
            " None\n",
            "-------------------------------------------------------\n",
            "Description of the dataset\n",
            "-------------------------------------------------------\n",
            "                  id\n",
            "count   3263.000000\n",
            "mean    5427.152927\n",
            "std     3146.427221\n",
            "min        0.000000\n",
            "25%     2683.000000\n",
            "50%     5500.000000\n",
            "75%     8176.000000\n",
            "max    10875.000000\n",
            "-------------------------------------------------------\n",
            "Checking duplication records\n",
            "-------------------------------------------------------\n",
            "0\n",
            "-------------------------------------------------------\n",
            "Droping the NaN values\n",
            "-------------------------------------------------------\n",
            "         id                                               text\n",
            "0         0                 Just happened a terrible car crash\n",
            "1         2  Heard about #earthquake is different cities, s...\n",
            "2         3  there is a forest fire at spot pond, geese are...\n",
            "3         9           Apocalypse lighting. #Spokane #wildfires\n",
            "4        11      Typhoon Soudelor kills 28 in China and Taiwan\n",
            "...     ...                                                ...\n",
            "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
            "3259  10865  Storm in RI worse than last hurricane. My city...\n",
            "3260  10868  Green Line derailment in Chicago http://t.co/U...\n",
            "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
            "3262  10875  #CityofCalgary has activated its Municipal Eme...\n",
            "\n",
            "[3263 rows x 2 columns]\n",
            "         id keyword location                                               text\n",
            "0         0     NaN      NaN                 Just happened a terrible car crash\n",
            "1         2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
            "2         3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
            "3         9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
            "4        11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
            "...     ...     ...      ...                                                ...\n",
            "3258  10861     NaN      NaN  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
            "3259  10865     NaN      NaN  Storm in RI worse than last hurricane. My city...\n",
            "3260  10868     NaN      NaN  Green Line derailment in Chicago http://t.co/U...\n",
            "3261  10874     NaN      NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
            "3262  10875     NaN      NaN  #CityofCalgary has activated its Municipal Eme...\n",
            "\n",
            "[3263 rows x 4 columns]\n",
            "-------------------------------------------------------\n",
            "Checking for Null\n",
            "-------------------------------------------------------\n",
            "id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7UgU7mkgPh"
      },
      "source": [
        "**1.6 Function for Cleaning of Text attribute**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohlybz1FkLXB"
      },
      "source": [
        "import re\n",
        "\n",
        "# helper function\n",
        "def clean_text(text):\n",
        "    te = str(text).encode('ascii','ignore').decode('UTF-8')\n",
        "    te = re.sub(r'@[\\w]+', '', te)\n",
        "    te = re.sub(r'https?://t.co/[\\w]+', '', te)\n",
        "    te = re.sub(r'#', '', te)\n",
        "    te = re.sub(r\"RT @[\\w]+:\",'',te)\n",
        "    te = re.sub(r\"RT @[\\w]+:\",'',te)\n",
        "    te = re.sub(r\" RT \",'',te)\n",
        "    te = re.sub(r\"https://[\\w]+.[\\w]+/[\\w]+\",'',te)\n",
        "    te = re.sub(r\"[][]\",'',te)\n",
        "    te = re.sub(r\"&amp\",\"and\", te)\n",
        "    # remove the characters [\\], ['] and [\"]\n",
        "    text = re.sub(r\"\\\\\", \"\", te)    \n",
        "    text = re.sub(r\"\\'\", \"\", text)    \n",
        "    text = re.sub(r\"\\\"\", \"\", text)    \n",
        "    \n",
        "    # convert text to lowercase\n",
        "    text = text.strip().lower()\n",
        "    \n",
        "    # replace punctuation characters with spaces\n",
        "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "    translate_dict = dict((c, \" \") for c in filters)\n",
        "    translate_map = str.maketrans(translate_dict)\n",
        "    text = text.translate(translate_map)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toxW6yIy6giT"
      },
      "source": [
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = stem_tokens(tokens, stemmer)\n",
        "    return stems"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEOgDRyPkqgk"
      },
      "source": [
        "**1.7 Importing the TfidfVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81FZUXRIkR8S"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1BDB8VCkyuo"
      },
      "source": [
        "**1.8 Converting the Train text attribute to vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRddFTEAlJUg",
        "outputId": "5115bef3-bab1-45e2-dc76-59382a7a49fb"
      },
      "source": [
        "# Transform each text into a vector of word counts\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
        "                             preprocessor=clean_text,\n",
        "                             ngram_range=(1, 2))\n",
        "\n",
        "training_features = vectorizer.fit_transform(train.text)\n",
        "print(training_features)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2974)\t0.3649935688089075\n",
            "  (0, 16347)\t0.3649935688089075\n",
            "  (0, 40813)\t0.3649935688089075\n",
            "  (0, 13634)\t0.3649935688089075\n",
            "  (0, 20169)\t0.348985065600402\n",
            "  (0, 2972)\t0.3014500197590137\n",
            "  (0, 16342)\t0.24206629634942667\n",
            "  (0, 40808)\t0.27215697795073607\n",
            "  (0, 13633)\t0.348985065600402\n",
            "  (1, 43393)\t0.3334119066241046\n",
            "  (1, 42558)\t0.3334119066241046\n",
            "  (1, 28701)\t0.3334119066241046\n",
            "  (1, 34463)\t0.3334119066241046\n",
            "  (1, 20129)\t0.3334119066241046\n",
            "  (1, 8607)\t0.26879103060431747\n",
            "  (1, 43392)\t0.3334119066241046\n",
            "  (1, 42557)\t0.3334119066241046\n",
            "  (1, 28695)\t0.24532720123790422\n",
            "  (1, 34441)\t0.21388380779579141\n",
            "  (1, 20117)\t0.20898604405838725\n",
            "  (2, 36424)\t0.21312416533699777\n",
            "  (2, 38190)\t0.21312416533699777\n",
            "  (2, 17624)\t0.21312416533699777\n",
            "  (2, 35860)\t0.21312416533699777\n",
            "  (2, 35352)\t0.21312416533699777\n",
            "  :\t:\n",
            "  (7611, 10865)\t0.1441933550265417\n",
            "  (7611, 6094)\t0.388853838688965\n",
            "  (7611, 35200)\t0.17039013073576756\n",
            "  (7611, 50135)\t0.18345453703215392\n",
            "  (7611, 26713)\t0.16727279844425907\n",
            "  (7611, 30321)\t0.14067234730523157\n",
            "  (7611, 42040)\t0.19017056534965782\n",
            "  (7611, 29670)\t0.1266923211444399\n",
            "  (7611, 38592)\t0.1183656325773651\n",
            "  (7611, 8759)\t0.12695028304001588\n",
            "  (7612, 55083)\t0.3003133493043367\n",
            "  (7612, 40527)\t0.2729290270829103\n",
            "  (7612, 24580)\t0.27152079474246316\n",
            "  (7612, 29007)\t0.2729290270829103\n",
            "  (7612, 40524)\t0.26632165850746103\n",
            "  (7612, 1912)\t0.2927399168227172\n",
            "  (7612, 1910)\t0.28078992697950755\n",
            "  (7612, 24568)\t0.24272824018058967\n",
            "  (7612, 8452)\t0.26511754881698635\n",
            "  (7612, 55082)\t0.2351548076989702\n",
            "  (7612, 35282)\t0.25754411633536684\n",
            "  (7612, 35280)\t0.23940335609737284\n",
            "  (7612, 29002)\t0.24272824018058967\n",
            "  (7612, 34831)\t0.19506643233616563\n",
            "  (7612, 8409)\t0.2157035641510873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMi4tLNylVxh"
      },
      "source": [
        "**1.9 Converting the Test text attribute to vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDKk0Wy2lKI8",
        "outputId": "710d09c9-eeee-4aa6-d35d-3f1b934773ff"
      },
      "source": [
        "# Transform each text into a vector of word counts\n",
        "vectorizer2 = TfidfVectorizer(stop_words=\"english\",\n",
        "                             preprocessor=clean_text,\n",
        "                             ngram_range=(1, 2))\n",
        "\n",
        "testing_features = vectorizer2.fit_transform(test.text)\n",
        "print(testing_features)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 4538)\t0.3713765914940486\n",
            "  (0, 25106)\t0.4047884285864036\n",
            "  (0, 11566)\t0.4047884285864036\n",
            "  (0, 13953)\t0.38524375680717177\n",
            "  (0, 6222)\t0.252611247851494\n",
            "  (0, 4530)\t0.26414285848614355\n",
            "  (0, 25105)\t0.3379647544016936\n",
            "  (0, 11559)\t0.3109895432701939\n",
            "  (0, 13902)\t0.20357005630725447\n",
            "  (1, 24038)\t0.32050990799481033\n",
            "  (1, 5260)\t0.3367704205743454\n",
            "  (1, 7467)\t0.3367704205743454\n",
            "  (1, 8262)\t0.3367704205743454\n",
            "  (1, 11816)\t0.3367704205743454\n",
            "  (1, 21857)\t0.27645186555739765\n",
            "  (1, 24034)\t0.2684042967218669\n",
            "  (1, 5257)\t0.2865304181646671\n",
            "  (1, 7466)\t0.30897289071646783\n",
            "  (1, 8256)\t0.24247237572725436\n",
            "  (1, 11815)\t0.24247237572725436\n",
            "  (2, 24281)\t0.3004375220980004\n",
            "  (2, 9939)\t0.3004375220980004\n",
            "  (2, 10615)\t0.3004375220980004\n",
            "  (2, 19550)\t0.3004375220980004\n",
            "  (2, 23812)\t0.3004375220980004\n",
            "  :\t:\n",
            "  (3260, 11190)\t0.35666020273370136\n",
            "  (3260, 5108)\t0.3736306103604052\n",
            "  (3260, 15128)\t0.32480145339038613\n",
            "  (3261, 16222)\t0.3394866595626963\n",
            "  (3261, 16221)\t0.3230949969903448\n",
            "  (3261, 18423)\t0.31146492731123837\n",
            "  (3261, 27663)\t0.31146492731123837\n",
            "  (3261, 11739)\t0.31146492731123837\n",
            "  (3261, 13555)\t0.31146492731123837\n",
            "  (3261, 12671)\t0.31146492731123837\n",
            "  (3261, 18422)\t0.31146492731123837\n",
            "  (3261, 11733)\t0.2554214628083225\n",
            "  (3261, 27654)\t0.24847410440883663\n",
            "  (3261, 13553)\t0.26705153248742897\n",
            "  (3262, 19289)\t0.3366845709496316\n",
            "  (3262, 1124)\t0.3366845709496316\n",
            "  (3262, 5291)\t0.3366845709496316\n",
            "  (3262, 5290)\t0.3366845709496316\n",
            "  (3262, 28723)\t0.30889412724707077\n",
            "  (3262, 1122)\t0.3204282035052311\n",
            "  (3262, 8542)\t0.27215715894726994\n",
            "  (3262, 17022)\t0.29994760264983084\n",
            "  (3262, 17021)\t0.29994760264983084\n",
            "  (3262, 8522)\t0.19357081354261163\n",
            "  (3262, 19272)\t0.23876322077734388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMNILVf7lnZ3"
      },
      "source": [
        "### **2.0 Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbR8Cueklqfq"
      },
      "source": [
        "**2.1 Importing the modules for model building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hokCiCIFlmyF"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.metrics import precision_score, recall_score, make_scorer, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGUlB6ImkTs"
      },
      "source": [
        "**2.2 Spliting the train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImcgdWzlKFf"
      },
      "source": [
        "# extract the labels from the train data\n",
        "y = train.target.values\n",
        "\n",
        "# use 70% for the training and 30% for the test\n",
        "x_train, x_test, y_train, y_test = train_test_split(train.text.values, y, \n",
        "                                                    stratify=y, \n",
        "                                                    random_state=1, \n",
        "                                                    test_size=0.3, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNhmw-kmBQT",
        "outputId": "922b0263-3f8f-4ddd-db47-8e7edd00e0aa"
      },
      "source": [
        "#@title\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5329,)\n",
            "(5329,)\n",
            "(2284,)\n",
            "(2284,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDO4bLPVmpS-"
      },
      "source": [
        "**2.3 Special Characters in RE library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXt9p3nWlKB9"
      },
      "source": [
        "# remove special characters using the regular expression library\n",
        "import re\n",
        "\n",
        "#set up punctuations we want to be replaced\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xyiGu5hm-wb"
      },
      "source": [
        "**2.3 Preprocessing the text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULRQfzY0lJ-V"
      },
      "source": [
        "import preprocessor as p\n",
        "\n",
        "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
        "def clean_tweets(df):\n",
        "  tempArr = []\n",
        "  for line in df:\n",
        "    # send to tweet_processor\n",
        "    tmpL = p.clean(line)\n",
        "    # remove puctuation\n",
        "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
        "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
        "    tempArr.append(tmpL)\n",
        "  return tempArr"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkD8S1B9nh6N"
      },
      "source": [
        "**2.4 Creating seperate dataFrame for Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XGwerW-Km5ni",
        "outputId": "f913f022-cc11-4c9c-a31e-95de2ea029b0"
      },
      "source": [
        "train_tweet = clean_tweets(train[\"text\"])\n",
        "train_tweet = pd.DataFrame(train_tweet)\n",
        "# append cleaned tweets to the training data\n",
        "train[\"clean_tweet\"] = train_tweet\n",
        "# compare the cleaned and uncleaned tweets\n",
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this may allah for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive evacuation orders in california</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target                                        clean_tweet\n",
              "0   1     NaN  ...      1  our deeds are the reason of this may allah for...\n",
              "1   4     NaN  ...      1              forest fire near la ronge sask canada\n",
              "2   5     NaN  ...      1  all residents asked to shelter in place are be...\n",
              "3   6     NaN  ...      1     people receive evacuation orders in california\n",
              "4   7     NaN  ...      1  just got sent this photo from ruby as smoke fr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYH02R6yrCdH"
      },
      "source": [
        "**2.5 Creating seperate dataFrame for Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nxHL82VVrNzY",
        "outputId": "79da4185-6c93-4306-e788-f55b2356ff57"
      },
      "source": [
        "# clean the test data and append the cleaned tweets to the test data\n",
        "test_text = clean_tweets(test[\"text\"])\n",
        "test_text = pd.DataFrame(test_text)\n",
        "# append cleaned tweets to the training data\n",
        "test[\"clean_text\"] = test_text\n",
        "\n",
        "# compare the cleaned and uncleaned tweets\n",
        "test.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>heard about is different cities stay safe ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>there is a forest fire at spot pond geese are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>apocalypse lighting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>typhoon soudelor kills in china and taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                         clean_text\n",
              "0   0  ...                 just happened a terrible car crash\n",
              "1   2  ...  heard about is different cities stay safe ever...\n",
              "2   3  ...  there is a forest fire at spot pond geese are ...\n",
              "3   9  ...                                apocalypse lighting\n",
              "4  11  ...         typhoon soudelor kills in china and taiwan\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRddlDgEsCDY"
      },
      "source": [
        "**2.6 Spliting the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVW-eBsJnEX4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# extract the labels from the train data\n",
        "y = train.target.values\n",
        "\n",
        "# use 70% for the training and 30% for the test\n",
        "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, \n",
        "                                                    stratify=y, \n",
        "                                                    random_state=1, \n",
        "                                                    test_size=0.3, shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G82XoHAcsHA-"
      },
      "source": [
        "**2.7 Importing the CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMcGUD6prYFF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GsqzxyPseou"
      },
      "source": [
        "**2.8 Optional Testing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "0FQS6yCZrX_h",
        "outputId": "6ff6248a-2232-492f-8bf6-be848d48c4b5"
      },
      "source": [
        "documents = [\"This is Import Data's Youtube channel\",\n",
        "             \"Data science is my passion and it is fun!\",\n",
        "             \"Please subscribe to my channel\"]\n",
        "\n",
        "# initializing the countvectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# tokenize and make the document into a matrix\n",
        "document_term_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# check the result\n",
        "pd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>channel</th>\n",
              "      <th>data</th>\n",
              "      <th>fun</th>\n",
              "      <th>import</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>my</th>\n",
              "      <th>passion</th>\n",
              "      <th>please</th>\n",
              "      <th>science</th>\n",
              "      <th>subscribe</th>\n",
              "      <th>this</th>\n",
              "      <th>to</th>\n",
              "      <th>youtube</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.349498</td>\n",
              "      <td>0.349498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.459548</td>\n",
              "      <td>0.349498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.459548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.459548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.343596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261314</td>\n",
              "      <td>0.343596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.522627</td>\n",
              "      <td>0.343596</td>\n",
              "      <td>0.261314</td>\n",
              "      <td>0.343596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.373022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.373022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490479</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        and   channel      data  ...      this        to   youtube\n",
              "0  0.000000  0.349498  0.349498  ...  0.459548  0.000000  0.459548\n",
              "1  0.343596  0.000000  0.261314  ...  0.000000  0.000000  0.000000\n",
              "2  0.000000  0.373022  0.000000  ...  0.000000  0.490479  0.000000\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "711i6QAUtSrx"
      },
      "source": [
        "**2.9 Fitting into CV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17emdsUJrXmo"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# vectorize tweets for model building\n",
        "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
        "\n",
        "# learn a vocabulary dictionary of all tokens in the raw documents\n",
        "vectorizer.fit(list(x_train) + list(x_test))\n",
        "\n",
        "# transform documents to document-term matrix\n",
        "x_train_vec = vectorizer.transform(x_train)\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mW1y5nrXg-"
      },
      "source": [
        "from sklearn import svm\n",
        "# classify using support vector classifier\n",
        "svm = svm.SVC(kernel = 'linear', probability=True)\n",
        "\n",
        "# fit the SVC model based on the given training data\n",
        "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
        "\n",
        "# perform classification and prediction on samples in x_test\n",
        "y_pred_svm = svm.predict(x_test_vec)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMAxLexlrXbW",
        "outputId": "9c99099e-f18b-4ae1-89b8-9e01f8c05f72"
      },
      "source": [
        "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for SVC is:  75.87565674255691 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujIGl8AqnQ0j"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ95ruJr5rUb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jws-qfSL5qC5"
      },
      "source": [
        "## **2.0 Implementing Grid SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BlIAL46A18"
      },
      "source": [
        "**2.1 Importing the modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMSSNUz5nQv5",
        "outputId": "debcbdfd-07c0-4e23-ff91-e45c21eefb4b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfXSpWL9nQse"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_83AovQ6GMy"
      },
      "source": [
        "**2.2 Displaying the test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RBFWA4eKnQjs",
        "outputId": "d323a67f-0cc7-441c-ea59-c91cb806eed8"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>heard about is different cities stay safe ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>there is a forest fire at spot pond geese are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>apocalypse lighting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>typhoon soudelor kills in china and taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                         clean_text\n",
              "0   0  ...                 just happened a terrible car crash\n",
              "1   2  ...  heard about is different cities stay safe ever...\n",
              "2   3  ...  there is a forest fire at spot pond geese are ...\n",
              "3   9  ...                                apocalypse lighting\n",
              "4  11  ...         typhoon soudelor kills in china and taiwan\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK_WDJIm6KtR"
      },
      "source": [
        "**2.3 Displaying Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NToE8ohe53pl",
        "outputId": "59ead1cd-7996-477b-aa90-3bb9b708c608"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this may allah for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive evacuation orders in california</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target                                        clean_tweet\n",
              "0   1     NaN  ...      1  our deeds are the reason of this may allah for...\n",
              "1   4     NaN  ...      1              forest fire near la ronge sask canada\n",
              "2   5     NaN  ...      1  all residents asked to shelter in place are be...\n",
              "3   6     NaN  ...      1     people receive evacuation orders in california\n",
              "4   7     NaN  ...      1  just got sent this photo from ruby as smoke fr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNvhmL_U6OJq"
      },
      "source": [
        "**2.4 Subsetting the Train Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B9qqrSifmECW",
        "outputId": "2f961524-5811-4f39-a039-5de245108c3b"
      },
      "source": [
        "data = [train['clean_tweet'], train[\"target\"]]\n",
        "\n",
        "headers = [\"clean_text\", \"target\"]\n",
        "\n",
        "train_new = pd.concat(data, axis=1, keys=headers)\n",
        "train_new.head()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>our deeds are the reason of this may allah for...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all residents asked to shelter in place are be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>people receive evacuation orders in california</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>just got sent this photo from ruby as smoke fr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  target\n",
              "0  our deeds are the reason of this may allah for...       1\n",
              "1              forest fire near la ronge sask canada       1\n",
              "2  all residents asked to shelter in place are be...       1\n",
              "3     people receive evacuation orders in california       1\n",
              "4  just got sent this photo from ruby as smoke fr...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0CMYDLu6cDI"
      },
      "source": [
        "**2.5 Spliting the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc60fLFBmD9q"
      },
      "source": [
        "train, test = train_test_split(train_new, test_size=0.2, random_state=1)\n",
        "X_train = train['clean_text'].values\n",
        "X_test = test['clean_text'].values\n",
        "y_train = train['target']\n",
        "y_test = test['target']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-rBuBSd6rrr"
      },
      "source": [
        "**2.6 Cross validation and grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVskaHRBmD4E"
      },
      "source": [
        "def tokenize(text): \n",
        "    tknzr = TweetTokenizer()\n",
        "    return tknzr.tokenize(text)\n",
        "\n",
        "def stem(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))\n",
        "\n",
        "en_stopwords = set(stopwords.words(\"english\")) \n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    analyzer = 'word',\n",
        "    tokenizer = tokenize,\n",
        "    lowercase = True,\n",
        "    ngram_range=(1, 1),\n",
        "    stop_words = en_stopwords)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2_QM6Pc6zIM"
      },
      "source": [
        "**2.7 Fitting and PipeLine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwzxlJQmDxv"
      },
      "source": [
        "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8SLWewAmDu9",
        "outputId": "c9022712-72c6-4a6d-baf0-ba8b9279202e"
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "pipeline_svm = make_pipeline(vectorizer, \n",
        "                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n",
        "\n",
        "grid_svm = GridSearchCV(pipeline_svm,\n",
        "                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n",
        "                    cv = kfolds,\n",
        "                    scoring=\"roc_auc\",\n",
        "                    verbose=1,   \n",
        "                    n_jobs=-1) \n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "grid_svm.score(X_test, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.853315221044216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tJYh_k8ioi6"
      },
      "source": [
        "**Built MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBf0WhuDipII",
        "outputId": "b46418b2-df8d-4fb3-9356-4d02edc06116"
      },
      "source": [
        "grid_svm"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('countvectorizer',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preproc...\n",
              "                                            class_weight='balanced', coef0=0.0,\n",
              "                                            decision_function_shape='ovr',\n",
              "                                            degree=3, gamma='scale',\n",
              "                                            kernel='linear', max_iter=-1,\n",
              "                                            probability=True, random_state=None,\n",
              "                                            shrinking=True, tol=0.001,\n",
              "                                            verbose=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1, param_grid={'svc__C': [0.01, 0.1, 1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti1TMpLh7CqV"
      },
      "source": [
        "**2.8 Calculating Accuracy, F1-Score , Precision and Recall**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDvWEP-xo7Ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5b70b9-97dd-4c9d-b639-c648502a4179"
      },
      "source": [
        "def report_results(model, X, y):\n",
        "    pred_proba = model.predict_proba(X)[:, 1]\n",
        "    pred = model.predict(X)        \n",
        "\n",
        "    auc = roc_auc_score(y, pred_proba)\n",
        "    acc = accuracy_score(y, pred)\n",
        "    f1 = f1_score(y, pred)\n",
        "    prec = precision_score(y, pred)\n",
        "    rec = recall_score(y, pred)\n",
        "    result = {'Accuracy': auc, 'F1-Score': f1, 'Accuracy': acc, 'Precision': prec, 'Recall': rec}\n",
        "    return result\n",
        "    \n",
        "report_results(grid_svm.best_estimator_, X_test, y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7905449770190414,\n",
              " 'F1-Score': 0.733500417710944,\n",
              " 'Precision': 0.789568345323741,\n",
              " 'Recall': 0.6848673946957878}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esa_HzT_Wxs"
      },
      "source": [
        "**2.9 User Engagement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUTEkr18po1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1caa12aa-4626-4120-ff76-7a1f561673e7"
      },
      "source": [
        "user_input = input(\"Enter the string: \")\n",
        "res = grid_svm.predict([user_input])\n",
        "if(res[0] == 0):\n",
        "  print(\"\\n Positive \\n\")\n",
        "else:\n",
        "  print(\"\\n Negative \\n\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the string: Just got sent this photo from Ruby #Alaska \n",
            "\n",
            " Positive \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5wUQRLEbaGg"
      },
      "source": [
        "**2.9 Saving the model using Joblib library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN3SDkqcRw-H",
        "outputId": "a1b23d5e-e8fd-4516-fd4e-de00c807eca7"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(grid_svm,'tweets_analysis')\n",
        "\n",
        "# Saving pipeline in a file"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweets_analysis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}